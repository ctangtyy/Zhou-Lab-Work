{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50251098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/c/ctang04/.local/lib/python3.9/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Installing & Loading Packages\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343fe558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the patient methylation profiles\n",
    "m_log1k_path = \"/u/home/c/ctang04/HBV_Code/data/data.log1k.txt\"\n",
    "donors_path = \"/u/home/c/ctang04/HBV_Code/data/donors.with.samples.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03f95fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antiviral Rx' 'IAH' 'IT' 'RP' 'RP and Cirrhosis'\n",
      " 'Antiviral Rx and Cirrh' 'SC' 'ICP' 'IAH and Cirrhosis'\n",
      " 'SC and Cirrhosis']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "# Read methylation profile\n",
    "m_log1k_df = pd.read_csv(m_log1k_path, sep='\\t', header=0, index_col=0)\n",
    "#print(m_log1k_df.columns)\n",
    "\n",
    "# Read donors file\n",
    "donors_df = pd.read_csv(donors_path, sep='\\t', header=0, quotechar='\"')\n",
    "\n",
    "# Remove duplicate samples by donor\n",
    "unique_donors_df = donors_df.drop_duplicates(subset='donor')\n",
    "\n",
    "# Get phase classes from the donors\n",
    "phases = unique_donors_df['phase_HBV'].unique()\n",
    "print(phases)\n",
    "\n",
    "# Define mapping between original phases and desired classes\n",
    "phase_mapping = {\n",
    "    \"Antiviral Rx\": \"Antiviral Rx\",\n",
    "    \"IAH\": \"IAH\",\n",
    "    \"IT\": \"IT\",\n",
    "    \"RP\": \"RP\",\n",
    "    \"RP and Cirrhosis\": \"Cirrhosis\",\n",
    "    \"Antiviral Rx and Cirrh\": \"Cirrhosis\",\n",
    "    \"SC\": \"SC\",\n",
    "    \"ICP\": \"ICP\",\n",
    "    \"IAH and Cirrhosis\": \"Cirrhosis\",\n",
    "    \"SC and Cirrhosis\": \"Cirrhosis\"\n",
    "}\n",
    "\n",
    "# Create a new column in the dataframe with the modified classes\n",
    "unique_donors_df.loc[:, 'modified_phase'] = unique_donors_df['phase_HBV'].map(phase_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5530acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"IT\": \"IT\",\n",
    "    \"IAH\": \"IAH\",\n",
    "    \"Antiviral Rx\": \"Other\",\n",
    "    \"ICP\": \"Other\",\n",
    "    \"RP\": \"RP\",\n",
    "    \"Cirrhosis\": \"Other\"\n",
    "}\n",
    "unique_donors_df.loc[:, 'modified_class'] = unique_donors_df['modified_phase'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01cfb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144560, 9)\n"
     ]
    }
   ],
   "source": [
    "# Subset unique_donors_df for the IT class (9)\n",
    "IT_class_df = unique_donors_df[unique_donors_df['modified_class'] == \"IT\"]\n",
    "\n",
    "# Extract sample names\n",
    "IT_sample_names = IT_class_df['sample'].tolist()\n",
    "\n",
    "# Subset m_log1k_df based on Active_sample_names\n",
    "IT_class_data = m_log1k_df.loc[:, IT_sample_names]\n",
    "\n",
    "print(IT_class_data.shape)   # Displaying the dimensions (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2931820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144560, 67)\n"
     ]
    }
   ],
   "source": [
    "# Subset unique_donors_df for the IAH (67)\n",
    "IAH_class_df = unique_donors_df[unique_donors_df['modified_class'] == \"IAH\"]\n",
    "\n",
    "# Extract sample names\n",
    "IAH_sample_names = IAH_class_df['sample'].tolist()\n",
    "\n",
    "# Subset m_log1k_df based on Active_sample_names\n",
    "IAH_class_data = m_log1k_df.loc[:, IAH_sample_names]\n",
    "\n",
    "print(IAH_class_data.shape)   # Displaying the dimensions (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d7589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144560, 33)\n"
     ]
    }
   ],
   "source": [
    "# Subset unique_donors_df for the RP (33)\n",
    "RP_class_df = unique_donors_df[unique_donors_df['modified_class'] == \"RP\"]\n",
    "\n",
    "# Extract sample names\n",
    "RP_sample_names = RP_class_df['sample'].tolist()\n",
    "\n",
    "# Subset m_log1k_df based on Active_sample_names\n",
    "RP_class_data = m_log1k_df.loc[:, RP_sample_names]\n",
    "\n",
    "print(RP_class_data.shape)   # Displaying the dimensions (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56226b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the DataFrames so that sample names are rows and methylation sites are columns\n",
    "IT_class_data_t = IT_class_data.T\n",
    "IAH_class_data_t = IAH_class_data.T\n",
    "RP_class_data_t = RP_class_data.T\n",
    "\n",
    "# Add a label column to each transposed DataFrame\n",
    "IT_class_data_t['label'] = 0  # Label for IT\n",
    "IAH_class_data_t['label'] = 1  # Label for IAH\n",
    "RP_class_data_t['label'] = 2  # Label for RP\n",
    "\n",
    "# Concatenate the transposed DataFrames along the rows (axis=0)\n",
    "combined_df = pd.concat([IT_class_data_t, IAH_class_data_t, RP_class_data_t])\n",
    "\n",
    "# Separate features and target\n",
    "X = combined_df.drop(columns=['label'])\n",
    "y = combined_df['label']\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bfba3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (87, 144560)\n",
      "X_test shape: (22, 144560)\n",
      "y_train shape: (87,)\n",
      "y_test shape: (22,)\n",
      "plasma-646-P9-CH             0\n",
      "plasma-649-t8-6day-P9-CH     0\n",
      "plasma-1626-P9-CH            0\n",
      "plasma-3869-P9-CH            0\n",
      "plasma-2457-P9-CH            0\n",
      "                            ..\n",
      "plasma-3409-P9-CH            2\n",
      "plasma-2502-P9-CH            2\n",
      "plasma-2738-P9-CH            2\n",
      "plasma-2577-5day-P9-CH       2\n",
      "plasma-2568-r1-4day-P9-CH    2\n",
      "Name: label, Length: 109, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to verify dimensions\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a854a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 144560)\n",
      "(54, 144560)\n",
      "(26, 144560)\n"
     ]
    }
   ],
   "source": [
    "# Separate the active and inactive groups in the training data\n",
    "X_train_IT = X_train[y_train == 0]\n",
    "X_train_IAH = X_train[y_train == 1]\n",
    "X_train_RP = X_train[y_train == 2]\n",
    "\n",
    "print(X_train_IT.shape)\n",
    "print(X_train_IAH.shape)\n",
    "print(X_train_RP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bdb1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#methylation_sites = X_train.columns\n",
    "#print(methylation_sites.shape)\n",
    "#print(X_train_active.shape)\n",
    "#print(X_train_inactive.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b4c63",
   "metadata": {},
   "source": [
    "# P value and Fold Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5f8640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10501, 3)\n",
      "(4350, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_active_IT = X_train_IT\n",
    "X_train_inactive_IAH = X_train_IAH\n",
    "\n",
    "methylation_sites = X_train_IT.columns\n",
    "\n",
    "p_values_ITvIAH = []\n",
    "fold_changes_ITvIAH = []\n",
    "\n",
    "for site in methylation_sites:\n",
    "    active_values = X_train_active_IT[site].values\n",
    "    inactive_values = X_train_inactive_IAH[site].values\n",
    "\n",
    "    # Perform Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(active_values, inactive_values, equal_var=False)\n",
    "    p_values_ITvIAH.append(p_val)\n",
    "\n",
    "    # Calculate fold change\n",
    "    pseudocount = 0.001\n",
    "    mean_active = np.mean(active_values)\n",
    "    mean_inactive = np.mean(inactive_values)\n",
    "    \n",
    "    if mean_inactive != 0:\n",
    "        fold_change = np.log2((mean_active + pseudocount) / (mean_inactive + pseudocount))\n",
    "    else:\n",
    "        fold_change = float('NaN')  # Handle division by zero case\n",
    "\n",
    "    fold_changes_ITvIAH.append(fold_change)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df_ITvIAH = pd.DataFrame({\n",
    "    'methylation_site': methylation_sites,\n",
    "    'p_value': p_values_ITvIAH,\n",
    "    'fold_change': fold_changes_ITvIAH\n",
    "})\n",
    "\n",
    "# Filter significant sites based on p-value thresholds\n",
    "significant_sites05_ITvIAH = results_df_ITvIAH[results_df_ITvIAH['p_value'] < 0.05]\n",
    "significant_sites05_ITvIAH.to_csv('/u/home/c/ctang04/HBV_Code/output/ITvIAH_p05_ttest_fold_change.csv', index=False)\n",
    "significant_sites01_ITvIAH = results_df_ITvIAH[results_df_ITvIAH['p_value'] < 0.01]\n",
    "significant_sites01_ITvIAH.to_csv('/u/home/c/ctang04/HBV_Code/output/ITvIAH_p01_ttest_fold_change.csv', index=False)\n",
    "\n",
    "# Print the number of significant sites\n",
    "print(significant_sites05_ITvIAH.shape)\n",
    "print(significant_sites01_ITvIAH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f4b313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7239, 3)\n",
      "(1901, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_active_IT = X_train_IT\n",
    "X_train_inactive_RP = X_train_RP\n",
    "\n",
    "methylation_sites = X_train_IT.columns\n",
    "\n",
    "p_values_ITvRP = []\n",
    "fold_changes_ITvRP = []\n",
    "\n",
    "for site in methylation_sites:\n",
    "    active_values = X_train_active_IT[site].values\n",
    "    inactive_values = X_train_inactive_RP[site].values\n",
    "\n",
    "    # Perform Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(active_values, inactive_values, equal_var=False)\n",
    "    p_values_ITvRP.append(p_val)\n",
    "\n",
    "    # Calculate fold change with pseudocount\n",
    "    pseudocount = 0.001\n",
    "    mean_active = np.mean(active_values)\n",
    "    mean_inactive = np.mean(inactive_values)\n",
    "    \n",
    "    if mean_inactive != 0:\n",
    "        fold_change = np.log2((mean_active + pseudocount) / (mean_inactive + pseudocount))\n",
    "    else:\n",
    "        fold_change = float('NaN')  # Handle division by zero case\n",
    "\n",
    "    fold_changes_ITvRP.append(fold_change)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df_ITvRP = pd.DataFrame({\n",
    "    'methylation_site': methylation_sites,\n",
    "    'p_value': p_values_ITvRP,\n",
    "    'fold_change': fold_changes_ITvRP\n",
    "})\n",
    "\n",
    "# Filter significant sites based on p-value thresholds\n",
    "significant_sites05_ITvRP = results_df_ITvRP[results_df_ITvRP['p_value'] < 0.05]\n",
    "significant_sites05_ITvRP.to_csv('/u/home/c/ctang04/HBV_Code/output/ITvRP_p05_ttest_fold_change.csv', index=False)\n",
    "significant_sites01_ITvRP = results_df_ITvRP[results_df_ITvRP['p_value'] < 0.01]\n",
    "significant_sites01_ITvRP.to_csv('/u/home/c/ctang04/HBV_Code/output/ITvRP_p01_ttest_fold_change.csv', index=False)\n",
    "\n",
    "# Print the number of significant sites\n",
    "print(significant_sites05_ITvRP.shape)\n",
    "print(significant_sites01_ITvRP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fc90cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5138, 3)\n",
      "(823, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_active_RP = X_train_RP\n",
    "X_train_inactive_IAH = X_train_IAH\n",
    "\n",
    "methylation_sites = X_train_RP.columns\n",
    "\n",
    "p_values_RPvIAH = []\n",
    "fold_changes_RPvIAH = []\n",
    "\n",
    "for site in methylation_sites:\n",
    "    active_values = X_train_active_RP[site].values\n",
    "    inactive_values = X_train_inactive_IAH[site].values\n",
    "\n",
    "    # Perform Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(active_values, inactive_values, equal_var=False)\n",
    "    p_values_RPvIAH.append(p_val)\n",
    "\n",
    "    # Calculate fold change with pseudocount\n",
    "    pseudocount = 0.001\n",
    "    mean_active = np.mean(active_values)\n",
    "    mean_inactive = np.mean(inactive_values)\n",
    "    \n",
    "    if mean_inactive != 0:\n",
    "        fold_change = np.log2((mean_active + pseudocount) / (mean_inactive + pseudocount))\n",
    "    else:\n",
    "        fold_change = float('NaN')  # Handle division by zero case\n",
    "\n",
    "    fold_changes_RPvIAH.append(fold_change)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df_RPvIAH = pd.DataFrame({\n",
    "    'methylation_site': methylation_sites,\n",
    "    'p_value': p_values_RPvIAH,\n",
    "    'fold_change': fold_changes_RPvIAH\n",
    "})\n",
    "\n",
    "# Filter significant sites based on p-value thresholds\n",
    "significant_sites05_RPvIAH = results_df_RPvIAH[results_df_RPvIAH['p_value'] < 0.05]\n",
    "significant_sites05_RPvIAH.to_csv('/u/home/c/ctang04/HBV_Code/output/RPvIAH_p05_ttest_fold_change.csv', index=False)\n",
    "significant_sites01_RPvIAH = results_df_RPvIAH[results_df_RPvIAH['p_value'] < 0.01]\n",
    "significant_sites01_RPvIAH.to_csv('/u/home/c/ctang04/HBV_Code/output/RPvIAH_p01_ttest_fold_change.csv', index=False)\n",
    "\n",
    "# Print the number of significant sites\n",
    "print(significant_sites05_RPvIAH.shape)\n",
    "print(significant_sites01_RPvIAH.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb07409f",
   "metadata": {},
   "source": [
    "# Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09f4f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 methylation_site   p_value  fold_change\n",
      "16      chr10_100992139_100992258  0.007114    -9.256017\n",
      "17      chr10_100992275_100992394  0.017237    -9.008365\n",
      "18      chr10_100992374_100992493  0.017165    -8.966021\n",
      "40      chr10_101089800_101089919  0.027449    -8.820565\n",
      "41      chr10_101089922_101090041  0.002009    -9.626346\n",
      "...                           ...       ...          ...\n",
      "121216     chr6_90120915_90121034  0.044997    -6.636230\n",
      "121515   chr7_132260465_132260584  0.025725     2.528339\n",
      "122693   chr8_145911314_145911433  0.047533          NaN\n",
      "122720     chr8_17658570_17658689  0.024195          NaN\n",
      "123445   chr9_132199788_132199907  0.046934          NaN\n",
      "\n",
      "[22878 rows x 3 columns]\n",
      "                 methylation_site   p_value  fold_change\n",
      "16      chr10_100992139_100992258  0.007114    -9.256017\n",
      "41      chr10_101089922_101090041  0.002009    -9.626346\n",
      "59      chr10_101287567_101287686  0.001957     0.583280\n",
      "80      chr10_101294629_101294748  0.004394    -9.304916\n",
      "111     chr10_102131089_102131208  0.004798    -0.108884\n",
      "...                           ...       ...          ...\n",
      "101372     chrX_40032104_40032223  0.009786     1.090740\n",
      "101531     chrX_53117912_53118031  0.009536     0.506498\n",
      "101730       chrX_9308892_9309011  0.006087     0.293365\n",
      "118250     chr3_98451691_98451810  0.005150     4.788858\n",
      "119636     chr5_31855140_31855259  0.002411     4.677501\n",
      "\n",
      "[7074 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "union_significant_sites05_1vRest = pd.concat([significant_sites05_ITvRP,significant_sites05_ITvIAH,significant_sites05_RPvIAH])\n",
    "union_significant_sites05_1vRest.drop_duplicates().reset_index(drop=True)\n",
    "print(union_significant_sites05_1vRest)\n",
    "\n",
    "union_significant_sites01_1vRest = pd.concat([significant_sites01_ITvRP,significant_sites01_ITvIAH,significant_sites01_RPvIAH])\n",
    "union_significant_sites01_1vRest.drop_duplicates().reset_index(drop=True)\n",
    "print(union_significant_sites01_1vRest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a6ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 methylation_site   p_value  fold_change\n",
      "10941   chr12_108238515_108238634  0.003872     2.071044\n",
      "16192     chr13_20806709_20806828  0.032935     2.226247\n",
      "16487     chr13_28368172_28368291  0.025739     2.391563\n",
      "16720     chr13_30982804_30982923  0.031446     2.220010\n",
      "23433     chr15_81073003_81073122  0.024460     2.403410\n",
      "...                           ...       ...          ...\n",
      "116112   chr2_219867615_219867734  0.038477     3.688468\n",
      "118249     chr3_98451598_98451717  0.018071     4.225913\n",
      "118250     chr3_98451691_98451810  0.005150     4.788858\n",
      "119636     chr5_31855140_31855259  0.002411     4.677501\n",
      "121515   chr7_132260465_132260584  0.025725     2.528339\n",
      "\n",
      "[1061 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "fold_change_threshold = 2\n",
    "significant_sites_05_fold_change = union_significant_sites05_1vRest[union_significant_sites05_1vRest['fold_change'] > fold_change_threshold]\n",
    "print(significant_sites_05_fold_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25e25fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 1061)\n",
      "(22, 1061)\n",
      "(87,)\n",
      "(22,)\n"
     ]
    }
   ],
   "source": [
    "significant_sites_05 = significant_sites_05_fold_change['methylation_site'].tolist()\n",
    "\n",
    "# Select significant features from the training and testing data\n",
    "X_train_significant = X_train[significant_sites_05]\n",
    "X_test_significant = X_test[significant_sites_05]\n",
    "\n",
    "\n",
    "print(X_train_significant.shape)\n",
    "print(X_test_significant.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4fdd248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6363636363636364\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 12  1]\n",
      " [ 0  5  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.63      0.92      0.75        13\n",
      "           2       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.43      0.40      0.38        22\n",
      "weighted avg       0.59      0.64      0.57        22\n",
      "\n",
      "AUC-ROC: 0.5558099308099308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "rf_model = RandomForestClassifier(\n",
    "    max_depth=None,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train_significant, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf_model.predict(X_test_significant)\n",
    "\n",
    "# Predict probabilities for AUC calculation\n",
    "y_pred_prob = rf_model.predict_proba(X_test_significant)\n",
    "\n",
    "# Check if the classification is binary or multiclass\n",
    "if len(set(y_train)) == 2:  # Binary classification\n",
    "    auc = roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "else:  # Multiclass classification\n",
    "    y_test_bin = label_binarize(y_test, classes=list(set(y_train)))\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_prob, multi_class='ovo')\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC-ROC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70dd538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "319 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "221 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/u/home/c/ctang04/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.86465625 0.8950419  0.90137099\n",
      " 0.84826646 0.8891274  0.90648338 0.87510739 0.90668651 0.90531344\n",
      " 0.85501679 0.89705267 0.90644772 0.85411935 0.90207071 0.91252387\n",
      " 0.87306555 0.90427739 0.90117674 0.89176629 0.89643967 0.88726385\n",
      " 0.89176629 0.89643967 0.88726385 0.88546287 0.89219974 0.88828949\n",
      " 0.9100324  0.91190587 0.91821581 0.89920954 0.90596834 0.9049932\n",
      " 0.90032606 0.89982476 0.89760975 0.91089646 0.91404124 0.91213675\n",
      " 0.91009962 0.91812243 0.92151127 0.91215188 0.89628441 0.90469017\n",
      " 0.9109707  0.9306678  0.93073024 0.9109707  0.9306678  0.93073024\n",
      " 0.90772866 0.92339216 0.9275358         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.86465625 0.8950419  0.90137099 0.84826646 0.8891274  0.90648338\n",
      " 0.87510739 0.90668651 0.90531344 0.85501679 0.89705267 0.90644772\n",
      " 0.85411935 0.90207071 0.91252387 0.87306555 0.90427739 0.90117674\n",
      " 0.89176629 0.89643967 0.88726385 0.89176629 0.89643967 0.88726385\n",
      " 0.88546287 0.89219974 0.88828949 0.90952735 0.9103808  0.91769522\n",
      " 0.89718934 0.90596834 0.90500874 0.89931596 0.89760254 0.89861985\n",
      " 0.90988636 0.91404124 0.91102564 0.91304876 0.91812243 0.92151127\n",
      " 0.91215188 0.89628441 0.90469017 0.9109707  0.9306678  0.93073024\n",
      " 0.9109707  0.9306678  0.93073024 0.90772866 0.92339216 0.9275358\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.86465625 0.8950419  0.90137099\n",
      " 0.84826646 0.8891274  0.90648338 0.87510739 0.90668651 0.90531344\n",
      " 0.85501679 0.89705267 0.90644772 0.85411935 0.90207071 0.91252387\n",
      " 0.87306555 0.90427739 0.90117674 0.89176629 0.89643967 0.88726385\n",
      " 0.89176629 0.89643967 0.88726385 0.88546287 0.89219974 0.88828949\n",
      " 0.9100324  0.91190587 0.91821581 0.89920954 0.90596834 0.9049932\n",
      " 0.90032606 0.89982476 0.89760975 0.91089646 0.91404124 0.91213675\n",
      " 0.91009962 0.91812243 0.92151127 0.91215188 0.89628441 0.90469017\n",
      " 0.9109707  0.9306678  0.93073024 0.9109707  0.9306678  0.93073024\n",
      " 0.90772866 0.92339216 0.9275358         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.86465625 0.8950419  0.90137099 0.84826646 0.8891274  0.90648338\n",
      " 0.87510739 0.90668651 0.90531344 0.85501679 0.89705267 0.90644772\n",
      " 0.85411935 0.90207071 0.91252387 0.87306555 0.90427739 0.90117674\n",
      " 0.89176629 0.89643967 0.88726385 0.89176629 0.89643967 0.88726385\n",
      " 0.88546287 0.89219974 0.88828949 0.9100324  0.91190587 0.91821581\n",
      " 0.89920954 0.90596834 0.9049932  0.90032606 0.89982476 0.89760975\n",
      " 0.91089646 0.91404124 0.91213675 0.91009962 0.91812243 0.92151127\n",
      " 0.91215188 0.89628441 0.90469017 0.9109707  0.9306678  0.93073024\n",
      " 0.9109707  0.9306678  0.93073024 0.90772866 0.92339216 0.9275358 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "[[ 0  2  0]\n",
      " [ 0 12  1]\n",
      " [ 0  5  2]]\n",
      "Class 0: Sensitivity (Recall) = 0.00, Specificity = 0.91\n",
      "Class 1: Sensitivity (Recall) = 0.92, Specificity = 0.67\n",
      "Class 2: Sensitivity (Recall) = 0.29, Specificity = 0.74\n",
      "Accuracy: 0.6363636363636364\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 12  1]\n",
      " [ 0  5  2]]\n",
      "ROC AUC: 0.5705331705331705\n",
      "Sensitivity: [0.         0.92307692 0.28571429]\n",
      "Specificity: [0.9090909090909091, 0.6666666666666666, 0.7368421052631579]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Define the scorer for AUC\n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True, multi_class='ovr')\n",
    "\n",
    "# Set up Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring=auc_scorer,\n",
    "                           cv=5,  # 5-fold cross-validation\n",
    "                           n_jobs=-1,  # Use all available cores\n",
    "                           verbose=0)\n",
    "\n",
    "# Fit the Grid Search to the training data\n",
    "grid_search.fit(X_train_significant, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_rf_model.predict(X_test_significant)\n",
    "y_pred_prob = best_rf_model.predict_proba(X_test_significant)\n",
    "\n",
    "# Calculate AUC\n",
    "if len(set(y_train)) == 2:  # Binary classification\n",
    "    auc = roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "else:  # Multiclass classification\n",
    "    y_test_bin = label_binarize(y_test, classes=list(set(y_train)))\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_prob, multi_class='ovo')\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Calculate sensitivity (recall) for each class\n",
    "sensitivity = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "# Calculate specificity for each class\n",
    "specificity = []\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    # True negatives (TN) for class i\n",
    "    TN = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]\n",
    "    # False positives (FP) and true negatives (TN) for class i\n",
    "    FP_plus_TN = np.sum(cm) - np.sum(cm[:, i])\n",
    "    # Specificity for class i\n",
    "    if FP_plus_TN == 0:\n",
    "        specificity_i = 0\n",
    "    else:\n",
    "        specificity_i = TN / FP_plus_TN\n",
    "    specificity.append(specificity_i)\n",
    "\n",
    "# Print results for sensitivity and specificity\n",
    "for i in range(cm.shape[0]):\n",
    "    print(f'Class {i}: Sensitivity (Recall) = {sensitivity[i]:.2f}, Specificity = {specificity[i]:.2f}')\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
