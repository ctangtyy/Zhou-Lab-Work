{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50251098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/c/ctang04/.local/lib/python3.9/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Installing & Loading Packages\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df78be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Or, ignore specific categories of warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343fe558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the patient methylation profiles\n",
    "m_log1k_path = \"/u/home/c/ctang04/HBV_Code/data/data.log1k.txt\"\n",
    "donors_path = \"/u/home/c/ctang04/HBV_Code/data/donors.with.samples.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03f95fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antiviral Rx' 'IAH' 'IT' 'RP' 'RP and Cirrhosis'\n",
      " 'Antiviral Rx and Cirrh' 'SC' 'ICP' 'IAH and Cirrhosis'\n",
      " 'SC and Cirrhosis']\n"
     ]
    }
   ],
   "source": [
    "# Read methylation profile\n",
    "m_log1k_df = pd.read_csv(m_log1k_path, sep='\\t', header=0, index_col=0)\n",
    "#print(m_log1k_df.columns)\n",
    "\n",
    "# Read donors file\n",
    "donors_df = pd.read_csv(donors_path, sep='\\t', header=0, quotechar='\"')\n",
    "\n",
    "# Remove duplicate samples by donor\n",
    "unique_donors_df = donors_df.drop_duplicates(subset='donor')\n",
    "\n",
    "# Get phase classes from the donors\n",
    "phases = unique_donors_df['phase_HBV'].unique()\n",
    "print(phases)\n",
    "\n",
    "# Define mapping between original phases and desired classes\n",
    "phase_mapping = {\n",
    "    \"Antiviral Rx\": \"Antiviral Rx\",\n",
    "    \"IAH\": \"IAH\",\n",
    "    \"IT\": \"IT\",\n",
    "    \"RP\": \"RP\",\n",
    "    \"RP and Cirrhosis\": \"Cirrhosis\",\n",
    "    \"Antiviral Rx and Cirrh\": \"Cirrhosis\",\n",
    "    \"SC\": \"SC\",\n",
    "    \"ICP\": \"ICP\",\n",
    "    \"IAH and Cirrhosis\": \"Cirrhosis\",\n",
    "    \"SC and Cirrhosis\": \"Cirrhosis\"\n",
    "}\n",
    "\n",
    "# Create a new column in the dataframe with the modified classes\n",
    "unique_donors_df.loc[:, 'modified_phase'] = unique_donors_df['phase_HBV'].map(phase_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5530acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    \"IT\": \"IT\",\n",
    "    \"IAH\": \"IAH\",\n",
    "    \"Antiviral Rx\": \"Other\",\n",
    "    \"ICP\": \"Other\",\n",
    "    \"RP\": \"RP\",\n",
    "    \"Cirrhosis\": \"Other\"\n",
    "}\n",
    "unique_donors_df.loc[:, 'modified_class'] = unique_donors_df['modified_phase'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01cfb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144560, 9)\n"
     ]
    }
   ],
   "source": [
    "# Subset unique_donors_df for the IT class (9)\n",
    "IT_class_df = unique_donors_df[unique_donors_df['modified_class'] == \"IT\"]\n",
    "\n",
    "# Extract sample names\n",
    "IT_sample_names = IT_class_df['sample'].tolist()\n",
    "\n",
    "# Subset m_log1k_df based on Active_sample_names\n",
    "IT_class_data = m_log1k_df.loc[:, IT_sample_names]\n",
    "\n",
    "print(IT_class_data.shape)   # Displaying the dimensions (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2931820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144560, 67)\n"
     ]
    }
   ],
   "source": [
    "# Subset unique_donors_df for the IAH (67)\n",
    "IAH_class_df = unique_donors_df[unique_donors_df['modified_class'] == \"IAH\"]\n",
    "\n",
    "# Extract sample names\n",
    "IAH_sample_names = IAH_class_df['sample'].tolist()\n",
    "\n",
    "# Subset m_log1k_df based on Active_sample_names\n",
    "IAH_class_data = m_log1k_df.loc[:, IAH_sample_names]\n",
    "\n",
    "print(IAH_class_data.shape)   # Displaying the dimensions (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29d7589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144560, 33)\n"
     ]
    }
   ],
   "source": [
    "# Subset unique_donors_df for the RP (33)\n",
    "RP_class_df = unique_donors_df[unique_donors_df['modified_class'] == \"RP\"]\n",
    "\n",
    "# Extract sample names\n",
    "RP_sample_names = RP_class_df['sample'].tolist()\n",
    "\n",
    "# Subset m_log1k_df based on Active_sample_names\n",
    "RP_class_data = m_log1k_df.loc[:, RP_sample_names]\n",
    "\n",
    "print(RP_class_data.shape)   # Displaying the dimensions (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56226b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the DataFrames so that sample names are rows and methylation sites are columns\n",
    "IT_class_data_t = IT_class_data.T\n",
    "IAH_class_data_t = IAH_class_data.T\n",
    "RP_class_data_t = RP_class_data.T\n",
    "\n",
    "# Add a label column to each transposed DataFrame\n",
    "IT_class_data_t['label'] = 0  # Label for IT\n",
    "IAH_class_data_t['label'] = 1  # Label for IAH\n",
    "RP_class_data_t['label'] = 2  # Label for RP\n",
    "\n",
    "# Concatenate the transposed DataFrames along the rows (axis=0)\n",
    "combined_df = pd.concat([IT_class_data_t, IAH_class_data_t, RP_class_data_t])\n",
    "\n",
    "# Separate features and target\n",
    "X = combined_df.drop(columns=['label'])\n",
    "y = combined_df['label']\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bfba3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (87, 144560)\n",
      "X_test shape: (22, 144560)\n",
      "y_train shape: (87,)\n",
      "y_test shape: (22,)\n",
      "plasma-646-P9-CH             0\n",
      "plasma-649-t8-6day-P9-CH     0\n",
      "plasma-1626-P9-CH            0\n",
      "plasma-3869-P9-CH            0\n",
      "plasma-2457-P9-CH            0\n",
      "                            ..\n",
      "plasma-3409-P9-CH            2\n",
      "plasma-2502-P9-CH            2\n",
      "plasma-2738-P9-CH            2\n",
      "plasma-2577-5day-P9-CH       2\n",
      "plasma-2568-r1-4day-P9-CH    2\n",
      "Name: label, Length: 109, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to verify dimensions\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a854a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 144560)\n",
      "(54, 144560)\n",
      "(26, 144560)\n"
     ]
    }
   ],
   "source": [
    "# Separate the active and inactive groups in the training data\n",
    "X_train_IT = X_train[y_train == 0]\n",
    "X_train_IAH = X_train[y_train == 1]\n",
    "X_train_RP = X_train[y_train == 2]\n",
    "\n",
    "print(X_train_IT.shape)\n",
    "print(X_train_IAH.shape)\n",
    "print(X_train_RP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bdb1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#methylation_sites = X_train.columns\n",
    "#print(methylation_sites.shape)\n",
    "#print(X_train_active.shape)\n",
    "#print(X_train_inactive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1566ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16305, 3)\n",
      "(8535, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_active_IT = X_train_IT\n",
    "X_train_inactive_Rest = pd.concat([X_train_IAH, X_train_RP])\n",
    "\n",
    "methylation_sites = X_train.columns\n",
    "\n",
    "p_values_ITvRest = []\n",
    "fold_changes_ITvRest = []\n",
    "\n",
    "for site in methylation_sites:\n",
    "    active_values = X_train_active_IT[site].values\n",
    "    inactive_values = X_train_inactive_Rest[site].values\n",
    "\n",
    "    # Perform Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(active_values, inactive_values, equal_var=False)\n",
    "    p_values_ITvRest.append(p_val)\n",
    "\n",
    "    # Calculate fold change with pseudocount\n",
    "    pseudocount = 0.001\n",
    "    mean_active = np.mean(active_values)\n",
    "    mean_inactive = np.mean(inactive_values)\n",
    "    \n",
    "    if mean_inactive != 0:\n",
    "        fold_change = np.log2((mean_active + pseudocount) / (mean_inactive + pseudocount))\n",
    "    else:\n",
    "        fold_change = float('NaN')  # Handle division by zero case\n",
    "\n",
    "    fold_changes_ITvRest.append(fold_change)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df_ITvRest = pd.DataFrame({\n",
    "    'methylation_site': methylation_sites,\n",
    "    'p_value': p_values_ITvRest,\n",
    "    'fold_change': fold_changes_ITvRest\n",
    "})\n",
    "\n",
    "# Filter significant sites based on p-value thresholds\n",
    "significant_sites05_ITvRest = results_df_ITvRest[results_df_ITvRest['p_value'] < 0.05]\n",
    "#significant_sites05_ITvRest.to_csv('/u/home/c/ctang04/HBV_Code/output/ITvRest_p05_ttest_fold_change.csv', index=False)\n",
    "significant_sites01_ITvRest = results_df_ITvRest[results_df_ITvRest['p_value'] < 0.01]\n",
    "#significant_sites01_ITvRest.to_csv('/u/home/c/ctang04/HBV_Code/output/ITvRest_p01_ttest_fold_change.csv', index=False)\n",
    "\n",
    "# Print the number of significant sites\n",
    "print(significant_sites05_ITvRest.shape)\n",
    "print(significant_sites01_ITvRest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfab7798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5841, 3)\n",
      "(1001, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_active_IAH = X_train_IAH\n",
    "X_train_inactive_Rest = pd.concat([X_train_IT, X_train_RP])\n",
    "\n",
    "methylation_sites = X_train.columns\n",
    "\n",
    "p_values_IAHvRest = []\n",
    "fold_changes_IAHvRest = []\n",
    "\n",
    "for site in methylation_sites:\n",
    "    active_values = X_train_active_IAH[site].values\n",
    "    inactive_values = X_train_inactive_Rest[site].values\n",
    "\n",
    "    # Perform Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(active_values, inactive_values, equal_var=False)\n",
    "    p_values_IAHvRest.append(p_val)\n",
    "\n",
    "    # Calculate fold change with pseudocount\n",
    "    pseudocount = 0.001\n",
    "    mean_active = np.mean(active_values)\n",
    "    mean_inactive = np.mean(inactive_values)\n",
    "    \n",
    "    if mean_inactive != 0:\n",
    "        fold_change = np.log2((mean_active + pseudocount) / (mean_inactive + pseudocount))\n",
    "    else:\n",
    "        fold_change = float('NaN')  # Handle division by zero case\n",
    "\n",
    "    fold_changes_IAHvRest.append(fold_change)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df_IAHvRest = pd.DataFrame({\n",
    "    'methylation_site': methylation_sites,\n",
    "    'p_value': p_values_IAHvRest,\n",
    "    'fold_change': fold_changes_IAHvRest\n",
    "})\n",
    "\n",
    "# Filter significant sites based on p-value thresholds\n",
    "significant_sites05_IAHvRest = results_df_IAHvRest[results_df_IAHvRest['p_value'] < 0.05]\n",
    "#significant_sites05_IAHvRest.to_csv('/u/home/c/ctang04/HBV_Code/output/IAHvRest_p05_ttest_fold_change.csv', index=False)\n",
    "significant_sites01_IAHvRest = results_df_IAHvRest[results_df_IAHvRest['p_value'] < 0.01]\n",
    "#significant_sites01_IAHvRest.to_csv('/u/home/c/ctang04/HBV_Code/output/IAHvRest_p01_ttest_fold_change.csv', index=False)\n",
    "\n",
    "# Print the number of significant sites\n",
    "print(significant_sites05_IAHvRest.shape)\n",
    "print(significant_sites01_IAHvRest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a30fc3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4756, 3)\n",
      "(805, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_active_RP = X_train_RP\n",
    "X_train_inactive_Rest = pd.concat([X_train_IT, X_train_IAH])\n",
    "\n",
    "methylation_sites = X_train.columns\n",
    "\n",
    "p_values_RPvRest = []\n",
    "fold_changes_RPvRest = []\n",
    "\n",
    "for site in methylation_sites:\n",
    "    active_values = X_train_active_RP[site].values\n",
    "    inactive_values = X_train_inactive_Rest[site].values\n",
    "\n",
    "    # Perform Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(active_values, inactive_values, equal_var=False)\n",
    "    p_values_RPvRest.append(p_val)\n",
    "\n",
    "    # Calculate fold change with pseudocount\n",
    "    pseudocount = 0.001\n",
    "    mean_active = np.mean(active_values)\n",
    "    mean_inactive = np.mean(inactive_values)\n",
    "    \n",
    "    if mean_inactive != 0:\n",
    "        fold_change = np.log2((mean_active + pseudocount) / (mean_inactive + pseudocount))\n",
    "    else:\n",
    "        fold_change = float('NaN')  # Handle division by zero case\n",
    "\n",
    "    fold_changes_RPvRest.append(fold_change)\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df_RPvRest = pd.DataFrame({\n",
    "    'methylation_site': methylation_sites,\n",
    "    'p_value': p_values_RPvRest,\n",
    "    'fold_change': fold_changes_RPvRest\n",
    "})\n",
    "\n",
    "# Filter significant sites based on p-value thresholds\n",
    "significant_sites05_RPvRest = results_df_RPvRest[results_df_RPvRest['p_value'] < 0.05]\n",
    "#significant_sites05_RPvRest.to_csv('/u/home/c/ctang04/HBV_Code/output/RPvRest_p05_ttest_fold_change.csv', index=False)\n",
    "significant_sites01_RPvRest = results_df_RPvRest[results_df_RPvRest['p_value'] < 0.01]\n",
    "#significant_sites01_RPvRest.to_csv('/u/home/c/ctang04/HBV_Code/output/RPvRest_p01_ttest_fold_change.csv', index=False)\n",
    "\n",
    "# Print the number of significant sites\n",
    "print(significant_sites05_RPvRest.shape)\n",
    "print(significant_sites01_RPvRest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15439638",
   "metadata": {},
   "source": [
    "# Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f4f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 methylation_site   p_value  fold_change\n",
      "0       chr10_100027865_100027984  0.016989    -7.359707\n",
      "13      chr10_100227770_100227889  0.013054    -7.381978\n",
      "16      chr10_100992139_100992258  0.000111    -8.487823\n",
      "17      chr10_100992275_100992394  0.000456    -8.335992\n",
      "18      chr10_100992374_100992493  0.000488    -8.237551\n",
      "...                           ...       ...          ...\n",
      "121894     chr7_29846363_29846482  0.047709    -6.804783\n",
      "122202     chr7_79764580_79764699  0.029163    -7.392649\n",
      "122693   chr8_145911314_145911433  0.047533          NaN\n",
      "122720     chr8_17658570_17658689  0.024195          NaN\n",
      "123445   chr9_132199788_132199907  0.046934          NaN\n",
      "\n",
      "[26902 rows x 3 columns]\n",
      "                 methylation_site   p_value  fold_change\n",
      "16      chr10_100992139_100992258  0.000111    -8.487823\n",
      "17      chr10_100992275_100992394  0.000456    -8.335992\n",
      "18      chr10_100992374_100992493  0.000488    -8.237551\n",
      "23      chr10_100993566_100993685  0.002660    -7.949635\n",
      "36      chr10_101089304_101089423  0.001947    -7.768646\n",
      "...                           ...       ...          ...\n",
      "101372     chrX_40032104_40032223  0.009790     1.063713\n",
      "101377     chrX_40034453_40034572  0.008454     2.581822\n",
      "101730       chrX_9308892_9309011  0.008620     0.262859\n",
      "118250     chr3_98451691_98451810  0.006955     3.805465\n",
      "119636     chr5_31855140_31855259  0.002300     4.846784\n",
      "\n",
      "[10341 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "union_significant_sites05_1vRest = pd.concat([significant_sites05_ITvRest,significant_sites05_IAHvRest,significant_sites05_RPvRest])\n",
    "union_significant_sites05_1vRest.drop_duplicates().reset_index(drop=True)\n",
    "print(union_significant_sites05_1vRest)\n",
    "\n",
    "union_significant_sites01_1vRest = pd.concat([significant_sites01_ITvRest,significant_sites01_IAHvRest,significant_sites01_RPvRest])\n",
    "union_significant_sites01_1vRest.drop_duplicates().reset_index(drop=True)\n",
    "print(union_significant_sites01_1vRest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25e25fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 methylation_site   p_value  fold_change\n",
      "9689      chr11_69634629_69634748  0.016766     2.779214\n",
      "10941   chr12_108238515_108238634  0.003203     2.437523\n",
      "11385   chr12_114877345_114877464  0.003504     2.344901\n",
      "15769   chr13_109148900_109149019  0.024788     2.195102\n",
      "15983   chr13_112758417_112758536  0.023857     2.442189\n",
      "...                           ...       ...          ...\n",
      "116112   chr2_219867615_219867734  0.036380     3.857768\n",
      "118249     chr3_98451598_98451717  0.017288     4.394382\n",
      "118250     chr3_98451691_98451810  0.006955     3.805465\n",
      "119636     chr5_31855140_31855259  0.002300     4.846784\n",
      "121515   chr7_132260465_132260584  0.021858     2.702360\n",
      "\n",
      "[923 rows x 3 columns]\n",
      "(87, 923)\n",
      "(22, 923)\n",
      "(87,)\n",
      "(22,)\n"
     ]
    }
   ],
   "source": [
    "fold_change_threshold = 2\n",
    "significant_sites_05_fold_change = union_significant_sites05_1vRest[union_significant_sites05_1vRest['fold_change'] > fold_change_threshold]\n",
    "print(significant_sites_05_fold_change)\n",
    "\n",
    "significant_sites_05 = significant_sites_05_fold_change['methylation_site'].tolist()\n",
    "\n",
    "# Select significant features from the training and testing data\n",
    "X_train_significant = X_train[significant_sites_05]\n",
    "X_test_significant = X_test[significant_sites_05]\n",
    "\n",
    "\n",
    "print(X_train_significant.shape)\n",
    "print(X_test_significant.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db1733af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6363636363636364\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 12  1]\n",
      " [ 0  5  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.63      0.92      0.75        13\n",
      "           2       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.43      0.40      0.38        22\n",
      "weighted avg       0.59      0.64      0.57        22\n",
      "\n",
      "AUC-ROC: 0.5769434269434269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "rf_model = RandomForestClassifier(\n",
    "    max_depth=None,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=200\n",
    ")\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train_significant, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf_model.predict(X_test_significant)\n",
    "\n",
    "# Predict probabilities for AUC calculation\n",
    "y_pred_prob = rf_model.predict_proba(X_test_significant)\n",
    "\n",
    "# Check if the classification is binary or multiclass\n",
    "if len(set(y_train)) == 2:  # Binary classification\n",
    "    auc = roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "else:  # Multiclass classification\n",
    "    y_test_bin = label_binarize(y_test, classes=list(set(y_train)))\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_prob, multi_class='ovr')\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC-ROC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32a7df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "[[ 0  2  0]\n",
      " [ 0 12  1]\n",
      " [ 0  5  2]]\n",
      "Class 0: Sensitivity (Recall) = 0.00, Specificity = 0.91\n",
      "Class 1: Sensitivity (Recall) = 0.92, Specificity = 0.67\n",
      "Class 2: Sensitivity (Recall) = 0.29, Specificity = 0.74\n",
      "Accuracy: 0.6363636363636364\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 12  1]\n",
      " [ 0  5  2]]\n",
      "ROC AUC: 0.6068477818477819\n",
      "Sensitivity: [0.         0.92307692 0.28571429]\n",
      "Specificity: [0.9090909090909091, 0.6666666666666666, 0.7368421052631579]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Define the scorer for AUC\n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True, multi_class='ovr')\n",
    "\n",
    "# Set up Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring=auc_scorer,\n",
    "                           cv=5,  # 5-fold cross-validation\n",
    "                           n_jobs=-1,  # Use all available cores\n",
    "                           verbose=0)\n",
    "\n",
    "# Fit the Grid Search to the training data\n",
    "grid_search.fit(X_train_significant, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_rf_model.predict(X_test_significant)\n",
    "y_pred_prob = best_rf_model.predict_proba(X_test_significant)\n",
    "\n",
    "# Calculate AUC\n",
    "if len(set(y_train)) == 2:  # Binary classification\n",
    "    auc = roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "else:  # Multiclass classification\n",
    "    y_test_bin = label_binarize(y_test, classes=list(set(y_train)))\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_prob, multi_class='ovr')\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Calculate sensitivity (recall) for each class\n",
    "sensitivity = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "# Calculate specificity for each class\n",
    "specificity = []\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    # True negatives (TN) for class i\n",
    "    TN = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]\n",
    "    # False positives (FP) and true negatives (TN) for class i\n",
    "    FP_plus_TN = np.sum(cm) - np.sum(cm[:, i])\n",
    "    # Specificity for class i\n",
    "    if FP_plus_TN == 0:\n",
    "        specificity_i = 0\n",
    "    else:\n",
    "        specificity_i = TN / FP_plus_TN\n",
    "    specificity.append(specificity_i)\n",
    "\n",
    "# Print results for sensitivity and specificity\n",
    "for i in range(cm.shape[0]):\n",
    "    print(f'Class {i}: Sensitivity (Recall) = {sensitivity[i]:.2f}, Specificity = {specificity[i]:.2f}')\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b889c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x2ab5c15abf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x2ab5c15abd30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5909090909090909\n",
      "Confusion Matrix:\n",
      "[[ 0  2  0]\n",
      " [ 0 11  2]\n",
      " [ 0  5  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.61      0.85      0.71        13\n",
      "           2       0.50      0.29      0.36         7\n",
      "\n",
      "    accuracy                           0.59        22\n",
      "   macro avg       0.37      0.38      0.36        22\n",
      "weighted avg       0.52      0.59      0.54        22\n",
      "\n",
      "AUC-ROC: 0.556496743996744\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='threadpoolctl')\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_significant, y_train)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the SMOTE-resampled training data\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf_model.predict(X_test_significant)\n",
    "\n",
    "# Predict probabilities for AUC calculation\n",
    "y_pred_prob = rf_model.predict_proba(X_test_significant)\n",
    "\n",
    "# Check if the classification is binary or multiclass\n",
    "if len(set(y_train)) == 2:  # Binary classification\n",
    "    auc = roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "else:  # Multiclass classification\n",
    "    y_test_bin = label_binarize(y_test, classes=list(set(y_train)))\n",
    "    auc = roc_auc_score(y_test_bin, y_pred_prob, multi_class='ovr')\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "print(f\"AUC-ROC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c036cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38c16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
